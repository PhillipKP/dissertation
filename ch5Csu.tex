\chapter{Computational Spectral Unmixing}\label{chap:Csu}

\section{Introduction}

In \Cref{chap:Afssic}, I argued that spectral classification is the goal of spectral imaging in most cases. However, in certain situations the analyst is interested in quantifying the presence of several materials in a single spatial location from a \gls{mixed spectrum}. Mixed spectra can occur when the sensor is part of a high-altitude platform such as an unmanned aerial vehicle (UAV) or satellite. The large standoff distances between the ground and the instrument result in large spatial resolutions. For example, in the Hyperion Imaging Spectrometer, which is satellite based, the spatial resolution is 30 meters \cite{folkman2001eo}. One cannot reasonably expect a single material to always occupy that large of an area. \Gls{spectral unmixing} is any procedure which attempts to take the measured spectrum of a mixed pixel and decompose it into a set of constituent spectra called the \glspl{endmember} and a set of corresponding fractions called the \glspl{fractional abundance}. 

Traditional spectral unmixing requires several seperate steps to quantify the fractional abunances. The isomorphic sensor must spatially or spectral scan the object scene, building the spectral datacube piece by piece. At each step, the restricted aperture or wavelength range rejects a significant fraction of the availiable light. A post-processing step is then used to reduce the size of the data to reduce the computational load. Finally an inversion step is used to compute the fractional abundances. Intuitively, the advantages of computational sensing discussed throughout this dissertation should be able to ameliorate some of the design trade-offs in traditional spectral unmixing.

In this chapter, I will talk about my efforts to apply the techniques of computational sensing to directly estimate the \gls{fractional abundance} without the need to reconstruct the spectral datacube. I will introduce a computational spectral imaging architecture called the \gls{lcsi}. I will then provide simulation results that demonstate the advantage of computational spectral unmixing using the \gls{afss} and the \gls{lcsi} over traditional architectures by leveraging the Fellgett and Jacquinot advantage with compressive sensing algorithms which promote sparse solutions. Results from a proof-of-principle experiment demonstrate the promise of computational spectral unmixing. 

\section{The Linear Mixing Model}

There are two main reasons why mixed spectra occur \cite{keshava2002spectral, keshava2003survey}. First, if the spatial resolution of the sensor is low enough, separate materials can jointly occupy the \acrfull{fov} of a single pixel, the resulting spectral measurement is a combination of the constituent spectra, see \Cref{fig:linearAndNonlinearMixing}(a). In this case, one can imagine the object scene as a \emph{checkerboard} mixture: light from the illumination source scatters or reflects from only one of the materials before being observed by the sensor, multiple scattering between materials are ignored. The second reason for mixed pixels occurs when different materials are combined into a homogeneous mixture, see \Cref{fig:linearAndNonlinearMixing}(b). In this case, mixed spectra are not caused by poor spatial resolution, they are inherent to the nature of the scene. For the purposes of this chapter I will focus on the first case, mixed spectra causes by the spatial resolution limitations of the sensor.

\begin{figure}
	\centering
	\includegraphics[scale=0.85]{linearAndNonlinearMixing.pdf}
	\captionof{figure}[Linear versus Non-Linear Mixing]{(a) Illustration of linear mixing where incident solar radiation reflects from a surface and the surface consists of distinct materials. (b) Illustration of nonlinear mixing where incident solar radiation encounters an intimate mixture of materials, reflecting or scattering multiple times before being reflected toward the spectral image sensor.}
	\label{fig:linearAndNonlinearMixing}
\end{figure}

When mixed spectra occur due to the spatial resolution limitation of the instrument, the fractional abundance is linearly proportional to the relative area of each material. This is called the \acrfull{lmm}, where the mixed spectrum can be written as 
%
\begin{equation}
\mb{f} = \sum_{r=1}^{N_{R}} x_r \mb{s}_r + \mb{e} = \mb{S} \mb{x}  + \mb{e}
\end{equation}
%
where $\mb{f}$ is the \gls{mixed spectrum}, $\mb{s}_r$ is the $r^{th}$ endmember spectrum, $\mb{S}$ is a matrix in which the columns are the endmember spectra, $\mb{x}$ is the fractional abundance vector, and $N_{R}$ is the number of endmembers in the endmember library, each spectra has \gls{numspecchan} spectral channels. In the \gls{lmm}, the interactions between distinct endmembers are assumed to be neglible \cite{clark1984reflectance}. 

There are two contraints imposed by the physics of the situation. Intuitively we should expect that the fractional abundance should be equal to or larger than zero. This is the \emph{nonnegativity} constraint:
%
\begin{equation}
	x_r \geq 0.
\end{equation}
%
We should also expect that if energy is conserved, i.e. there is no absorption of light, then the \gls{fractional abundance} should sum to one. This is the \emph{additivty} constraint:
%
\begin{equation}
	\sum_{r = 1}^{N_{R}} x_r = 1
\end{equation}


\subsection{Unmixing in Traditional Spectral Imaging}

In traditional spectral imaging, the spectral datacube is first isomorphically acquired by the instrument before any unmixing step is performed. Often a \gls{dimensionality reduction} step is used to reduce the computational burden of processing the spectral datacube \cite{keshava2002spectral, keshava2003survey}. If the endmembers are unknown, an \gls{endmember determination} step is executed. Finally, the \gls{inversion} step is used to estimate the fractional abundances. 

Notable data reduction algorithms include \acrfull{pca} and \acrfull{mnf}. As described in Chapter 2, \gls{pca} is applied to the measured data and finds the basis which decorrelates the data. In \gls{pca} one typically observes a steadily decreasing signal-to-noise ratio as the principal compenent number increases \cite{green1988transformation}. However, this is not always the case, since it equates variance with information and is based on the assumption that the data structure can be described by a multi-dimensional normal distribution \cite{philpot2015mnf}. In \gls{mnf}, the algorithm attempts to order the components in terms of \gls{snr} which consists of two seperate \gls{pca} rotations and a noise whitening step. \gls{mnf} requires estimation of the noise covariance matrix in addition to the covariance of the data.

%A non-statistical technique for dimensionality reduction is the optical real-time adaptive spectral identification system (ORASIS) \cite{bowles2007optical}, which is a series of steps that identify a subset of representative, or exemplar, pixels that convey the variables in a scene. When a new pixel is collects from the scene, a spectrum is compared to each examplar pixel using this angle metrix. If it is sufficently different then it is added to the set. Then using a modified Gram-Schmidt process, an orthogoal basis is created and a new dimension is added until the every exemplar can be represented well within a certain tolerances \cite{keshava2003survey}. 

The inversion step actually estimates the \gls{fractional abundance}. There are a variety of inversion techniques which actually attempt to estimate the fractional abundance vector. Many are based on minimizing the squared error and attempt to enforce additivity or non-negativity \cite{keshava2003survey, lawson1995solving}. There are various algorithms based on \acrfull{map}, \acrfull{mle}, and clustering which can be used for spectral unmxing. Unfortunately, we cannot explore each inversion technique, however due to their prevalence, I will use least-squares based inversion technique when comparing computational spectral unmixing techniques to tradiational unmixing techniques.

\section{Architecture}

In this research, two seperate architectures are used for spectral unmixing. The first architecture is the \gls{afss}, which is the single pixel version of the \gls{afssi-c} described in depth in \Cref{chap:Afssic}. The second architecture is a \acrfull{lcos} based spectral imager, called the \gls{lcsi}, which allows for an extremely compact instrument, see \Cref{fig:lcsiArchi}. The system provides a programmable spectral filter, which can be independently addressed at each physical pixel of the \gls{slm}. The device consists of an array of micro cells of liquid crystal on a reflecting layer \cite{lazarev2012lcos}. Each layer of liquid crystal can be modeled as a thin retarder plate. Since the birefringent phase retarder is sensitive to wavelength, the \gls{lcos} combined with a polarizing beam splitter or a linear polarizer produces a wavelength dependent transmission pattern, a spectral filter, which modulates the input spectra \cite{yuan2015compressive}.

\begin{figure}
	\includegraphics[scale=1.0]{lcsiArchi.pdf}
	\captionof{figure}[LCOS Based Spectral Imager]{The LCOS Spectral Imager. Light from the intermediate image plane is collimated. A polarizing beam splitter passes p-polarized light and rejects s-polarized light. Upon reflection of the LCOS SLM, the polarization state is changed to some elliptical polarization state. Only the s-polarized portion of the elliptical polarization is reflected toward the upper part where it is imaged onto a scientific camera. The intensity of the light that is passed depends on birefringence created by the programmable LCOS.}
	\label{fig:lcsiArchi}
\end{figure}

%\subsection{How the LCOS Creates Spectral Filters}
% Imagine an incident monochromatic plane wave traveling in the z-direction with a Jones polarization vector 
% \begin{equation}
% \mbh{a} = 
% 	\begin{bmatrix}
%     	a_{x}  \\
%     	a_{y} e^{ i \phi  }  \\
%    \end{bmatrix}
% \end{equation}
% %
% where $\phi$ is the phase differene between the x and y axes \cite{milster2013notes}. The full plane wave for the electric field can be written as

% \begin{equation}
% \mb{E} = A \exp \left[ \mb{k} \cdot \mb{r} - \omega t \right] \mbh{a}
% \end{equation}
% %
% where there leading $A$ is a complex constant that adjusted for amplitude and absolute phase shift.
% %
% \begin{equation}
% 	\mb{k} = k \mbh{k} = k \ap{ \alpha \mbh{x} + \beta \mbh{y} + \gamma \mbh{z} }
% \end{equation}
% %
% is the propagation vector with wavenumber $k = 2\pi /\ \lambda$ and direction cosines $\ap{\alpha, \beta, \gamma}$.

% Transmitting through the polarizing beam splitter only passes horizontally polarized light

% \begin{equation}
% 	\begin{bmatrix}
% 		a_x \\
% 		0 
% 	\end{bmatrix}
% 	=
% 	\begin{bmatrix}
% 		1 & 0 \\
% 		0 & 0
% 	\end{bmatrix}
% 	\begin{bmatrix}
% 		a_x  \\
% 		a_y e^{ i \phi  }
% 	\end{bmatrix}
% 	\label{eq:jonesAfterPBS1}
% \end{equation}

% The \gls{lcos} in our architecture is a phase only reflective type. Liquid crystal is used because it has the ability change birefringence $\Delta n$ when an electric field is applied. Birefringence is defined as 
% %
% \begin{equation}
% 	\Delta n = n_e - n_0
% \end{equation}
% %
% where $n_0$ is the ordinary refractive index and $n_e$ is the extraordinary refractive index \cite{zhang2014fundamentals}. By changing the electric field in the cell the $\Delta n$ is changed. 

% Birefringence is utilized to create retardation plates. These retardation plates serve to change the polarization state of input light. If one aligns the retardation plate so that the x polarized light is incident on the ordinary refractive index and the y polarized light is incident onto the ordinary refractive index then x and y polarizations are phase shifted by
% %
% \begin{equation}
% 	\eta = \frac{2 \pi}{\lambda} \left[ n_e\ap{\lambda} - n_o \ap{\lambda} \right] T
% \end{equation}
% %
% where $T$ is the physical thickness of the plate, where the $ n_e \ap{ \lambda } $ and $ n_o \ap{\lambda} $ are index of refraction of the extraordinary and ordinary waves which are wavelength dependant functions \cite{milster2013notes}. 

%The general Jones matrix for an arbitrary birefringent material as a retardation plate is
%
%\begin{equation}
%	\begin{bmatrix}
%		M_{11} & M_{12} \\
%		M_{21} & M_{22}
% 	\end{bmatrix}
% 	=
% 	\begin{bmatrix}
% 		e^{i \eta/2} \cos^2 \theta + e^{-i \eta/2} \sin^2 \theta & \ap{ e^{i \eta/2} - e^{-i \eta/2} } e^{-i \phi} \cos \theta \sin \theta \\
% 		\ap{ e^{i \eta/2} - e^{-i \eta/2} } e^{i \phi} \cos \theta \sin \theta & e^{i \eta/2} \sin^2 \theta + e^{-i \eta/2} \cos^2 \theta
% 	\end{bmatrix}
% 	\label{eq:arbJonesMatrix}
% \end{equation}
% %
% where the relative phase retardation between the fast and slow axes is given by $\eta = \phi_y - \phi_x$, $\theta$ is the orientation of the fast axis with respect to the x-axis, and $\phi$ is the circularity. Thus after propagating from the LCOS the Jones Vector is written as
% %
% \begin{equation}
% 	\begin{bmatrix}
% 		a_x M_{11} \\
% 		a_x M_{21}
% 	\end{bmatrix}	
% \end{equation}
% %
% finally the vertical polarization (y) is reflected by the polarizing beam splitter towards the camera
% %
% \begin{equation}
% 	\begin{bmatrix}
% 		0 \\
% 		a_x M_{21}
% 	\end{bmatrix}	
% \end{equation}

% Where the intensity is pro



% The phase shift can be used to change the polarization state of the light. For example, when linearly polarized light at 45 degrees goes through a phase shift of $\Delta = \lambda / 2$ the polarized light will rotate to vertical. However, this is a special case and in general the output light will be elliptically polarized. When elliptically polarized light is incident onto a linear polarizer, only linearly polarized light is passed, the intensity of the light passed however depends on the relative amplitude and phase of the x and y polarizations of the incident light \cite{milster2013notes}. 

Unfortunately, a full discussion of polarization is not appropriate for this dissertation. The important point is that for light of a single wavelength, the \gls{lcos} produces polarization which in general is not linearly polarized. Placing a linear polarizer after the light has been reflected from the \gls{lcos} will then force the transmitted light to be linearly polarized but at an intensity that depends on the projection of the output polarization from the LCOS onto the transmission direction of the polarizer. Passing non-monochromatic light to an \gls{lcos} and then a linear polarizer will impart a wavelength dependent intensity. In short, the \gls{slm} provides polarization and wavelength dependent transmission patterns to encoded the spectral datacube \cite{tsai2015spatial}.

\subsection{Forward Model}

The forward model for the \gls{lcsi} is similar to the forward model for the \gls{afssi-c} presented in \Cref{ssec:afssicForwardModel}, except now one does not need to account for the dispersion when imaging from the input plane to the LCOS and from the LCOS to the \gls{fpa} of the camera. I will thus skip the derivation of the forward model and simply present the final equation for the measurement value at pixel $n$ and $l$ from the camera:
%
\begin{align} 
	\Gamma_{nl} &= \sum_{n^\prime l^\prime} \iiint \mbox{rect} \left( \frac{x}{\Delta} - l, \frac{y}{\Delta} - n \right) \mbox{rect} \left( \frac{x}{\Delta} - l^\prime , \frac{y}{\Delta} - n^\prime \right) \notag \\
 	&\qquad \times T_{n^\prime l^\prime} \ap{\lambda} D_0 \left( x, y; \lambda \right) dx \, dy \, d\lambda.
\end{align}
%
Notice that there is no dispersion constraint like the one created in the \gls{afssi-c} or a joint spatial-spectral contraints like in the \gls{cassi}. The \gls{lcos} creates dispersion by the very nature of wavelength dependant birefringence. If one so choose to, one can simply treat each pixel in the image as completely indepdent from neighboring pixels. This greatly simplifies the analysis. 

Similar to the \gls{afssi-c} we can further simplify this by imagining a discrete spectral density, the spectral datacube. The discretized source spectral datacube is $D$, and then the detector signal $\Gamma$ is a result of spectral filter created by the \gls{pbs} and LCOS combination where spectral filter $T$ acting on the pixelated source is
%
%
\begin{equation}
	\Gamma_{n,l} = \sum^{N_{\lambda}-1}_{c = 0} T_{n,l,c} D_{n,l,c} \,
\end{equation}
%
%
which shows the measurement at each pixel being the inner product of the source spectrum and the spectral filter created by the \gls{pbs}-\gls{lcos} combination. In a single spatial location, this reduces to a simple inner product
%
\begin{equation}
	g_m = \mb{h}_m^{T} \mb{f} 
\end{equation}
%
where the subscript $m$ represents the $m^{\text{th}}$ measurement step and $\mb{f}$ the true spectrum at that pixel. For a sequence of measurements this simplies to 
%
\begin{equation}
	\mb{g} = \mb{H} \mb{f}
\end{equation}
%
where the $m^{th}$ row of $\mb{H}$ is $\mb{h}_m^T$ and $\mb{g}$ is an $N_m \times$1 vector, $\mb{f}$ is the ground truth mixed spectrum
%
\begin{equation}
	\mb{f} = \mb{S}\mb{x}
\end{equation}
%
Thus for a sequence of noisy measurements at a single pixel
%
\begin{equation}
	\mb{g} = \mb{H}\mb{S}\mb{x} + \mb{e} = \mb{A}\mb{x} + \mb{e}
\end{equation}\label{eq:csuForwardModel}
%
where $\mb{H}$ is an $N_m \times N_{\lambda}$ matrix, $\mb{S}$ is the endmember library which is an $N_{\lambda} \times N_{R}$ matrix, $\mb{x}$ is the fractional abundance vector which an $N_R \times 1$ vector, $\mb{e}$ is the additive noise which is a $N_m \times 1$ vector. If I define
%
\begin{equation}
	\mb{A} = \mb{H} \mb{S},
\end{equation}
%
One can think of $\mb{H}$ as the sensing matrix and $\mb{S}$ as the representation matrix as discussed in \Cref{sec:compressiveSesing}.


\section{Solving the Inverse Problem}

For this work I chose to use the least-squares estimator (LSE)
%
\begin{equation}
	\mbh{x} = \ap{ \mb{A}^T \mb{A} }^{-1} \mb{A}^T \mb{g}
\end{equation}\label{eq:lseEquationChap5}
%
to demonstrate the advantage provided by multiplexing without using compressive sensing based algorithms. To demonstrate compressive sensing approaches, I will used the built-in MATLAB \texttt{lasso} function which attempts to minimize the $\ell_1$ regularized least-squares objective function 
%
\begin{equation}
	\mbh{x} = \argminA_{\mb{x}} \: \| \mb{Ax} - \mb{g} \|_{2}^{2} + \tau \| \mb{x} \|_1
	\label{eq:l1reglsV2}
\end{equation}
%
in order to find fractional abundances that are sparse. 

In the traditional spectral imager, the fractional abundance is estimated after the spectral datacube is acquired. In our work, the fractional abundance can be estimated after each measurement step. However, since we need a way to compare our results to traditional spectral imaging, we can use the tunable filter architectures for a baseline comparision. The tunable filter acquires a single wavelength over the entire field-of-view and thus allows us to obtain measurements in a time sequential manner. This means that we can use the LSE to get an idea of how a traditional spectral imaging architecture would perform.

As I mentioned earlier, in remote sensing the fractional abundance vector $\mb{x}$ tends to be sparse: the number of endmembers in the library is much larger than number of endmembers that are actually present in the mixed spectrum $N_{R} > \| \mb{x} \|_0$. Therefore, one can invoke the techniques designed for compressive sensing to find solutions that are sparse.

\section{Prior work}


\subsection{Prior Efforts in Computational Spectral Unmixing}

Several researchers have shown promising results in applying compressive sensing to spectral unmixing using a modified single-pixel camera architecture \cite{li2012compressive}. They demonstrated the ability to reconstruct the fractional abundance planes without the need to explicitly reconstruct the spectral datacube. In this approach, the object scene is imaged onto a \gls{dmd} and then a condensor lens focuses the reflected light into a whiskbroom spectrometer. One can think of this architecture as a set of parallel single-pixel cameras each operating at a different spectral channel, with the constraint that each \gls{dmd} must display the same pattern. This architecture does not code the spectral dimension of the spectral datacube. The researchers demonstrated compressive unmixing by minimizing the total variation (TV) of the endmember images while enforcing the nonnegativity constraint. 

In another effort, researchers use the \acrfull{cassi} architecture to perform compressive sensing on the spectral datacube and solve the $\ell_1$-regularized least squares problem (lasso in regression) to promote sparsity in the fractional abundances \cite{monsalve2015spectral}. Due to the nature of the single-disperser \gls{cassi} architecture, the researchers are forced to solve a larger joint-inference problem to preform spectral unmixing. 

\subsection{Prior efforts using LCOS Computational Spectral Imaging}

Several groups have previously demonstrated computational spectroscopy and spectral imaging results using variations of liquid crystal technology. The first instance, in 2012, used a single-pixel liquid crystal device to demonstrate compressive spectroscopy and exhibited a 10$\times$ reduction in the number of measurements compared to a traditional ismorphic spectrometer \cite{august2013compressive}. Shortly after in 2013, a demonstration of a compressive spectral imager using an \gls{lcos} \gls{slm} was published which jointly coded spatial and spectral features \cite{zhu2013coded}. In 2015, an \gls{lcos} based hyperspectral imaging sensor demonstrated blind compressive sensing, using a Bayesian approach to dictionary learning \emph{in situ} \cite{yuan2015compressive}. That same year, a miniture ultraspectral imaging system based on a custom built liquid crystal cell, which applies the same spectral filter to each spatial location, demonstrated the ability to reconstruct gigapixel spectral datacubes with an order of magnitude reduction in measurement steps compared to isomorphic systems \cite{august2016miniature}. However, to my knowledge, no one has ever attempted to perform direct spectral unmixing using an \gls{lcos} based device. 


\section{Design and Selection of Spectral Filters for Unmixing}


\subsection{Adaptive Unmixing Algorithm For the AFSSI-C}\label{sec:unmixingAlgo}


The \acrfull{afss} has the ability to display psuedo-arbitrary spectral filters with the restriction of using binary codes $ \{ -1, +1 \}$ using the \gls{dmd}. In the \gls{afss}, one can emulate a tunable filter spectrometer by measuring one spectral channel at time, i.e. turn on one mirror per measurement step. In this case, the measurement matrix is equal to the identity matrix $\mb{H} = \mb{I}$. Combining the tunable filter approach with the LSE produces what one should expect from a traditional isomorphic spectrometer to conduct spectral unmixing.

We can also use random binary codes to achieve a multiplexed measurement to improve the throughput of each measurement to reduce the unmixing error. The spectrum can then be estimated by processing the measurement with the LSE to demonstrate the performance gained by collecting more light per measurement step. However, estimating the fractional abundance using a compressive sensing based algorithm such as the MATLAB \texttt{lasso} function can produce even better unmixing results by enforcing sparsity. 

As shown in the \gls{afssi-c}, adaptive coding can significantly improve performance compared to multiplexing alone. We developed an algorithm for adaptively creating spectral filters which uses a modified version of \gls{ppca} to create adaptive spectral filters. This algorithm begins with the spectral library which consist of the each endmember spectra $\mb{S}$. Initially, before any measurements are made, the estimated fractional abundance of each endmember is assumed to be the same: 
%
\begin{equation}
	\mbh{a}_{m=0} = 
	\begin{bmatrix}
	\frac{1}{N_R} \\
	\frac{1}{N_R} \\
	\vdots \\
	\frac{1}{N_R}
	\end{bmatrix}
\end{equation}
%
where $N_R$ is the number of endmembers. The subscript denotes the $m^{th}$ measurement step. Before any measurement is made, $m=0$. Then each endmember in the spectral library is weighted by the square of their respective estimated fractional abundance
%
\begin{equation}
	\mb{S}_w = 
	\begin{bmatrix}
		\hat{a}_1^2 \mb{s}_1 & \hat{a}_2^2 \mb{s}_2 & \hdots & \hat{a}_{N_R}^2 \mb{s}_{N_R}
	\end{bmatrix}
	\label{eq:weightedSpectralLibrary}
\end{equation}
%
this is called the weighted spectral library. Then the eigenvectors of the unnormalized covariance matrix of the weighted spectral library are computed to obtain the principal components
%
\begin{equation}
	\mb{X}_m = \mb{S}_w \mb{S}_w^T.
\end{equation}
%
Where the first principal component corresponds to the direction of largest variance and so on. Initially, for the first measurement, the algorithm chooses the first principal component for the spectral filter $\mb{h}_{m=1} = \mb{p}_1$. The measurement is then recorded
%
\begin{equation}
	g_{m=1} = \mb{h}_{m=1}^{T} \mb{f} + e_{m}
\end{equation}
%
A simulated ``guess'' measurement based on the current estimated fractional abundance $\mbh{a}_{m -1}$ is also computed:
% 
\begin{equation}
	\gamma_{m=1} = \mb{h}_{m=1}^{T} \mb{S} \mbh{a}_{m=0}
\end{equation}
%
notice that the guess measurement does not include any simulated noise. Remember $\mb{S}$ denotes the original spectral library matrix, not the weighted spectral library matrix. After the measurement is recorded, the $\ell_2$ norm of the difference between the guess measurement and the actual measurement is recorded:
%
\begin{equation}
	\xi_m = \| \gamma_m - g_m \|_2 
\end{equation}
%
The fractional abundance is then estimated using the MATLAB \texttt{lasso} function. In practice, the LSE is used for the first measurement step since the function \texttt{lasso} requires atleast two rows for $\mb{A}$ and therefore two measurements, to run. 

The spectral library is then reweighted using \Cref{eq:weightedSpectralLibrary}. Again the principal components are recomputed. For the $m^{th}$ measurement step, the $m^{th}$ principal component is used for the spectral filter. After the measurement has been recorded, the  $\ell_2$ norm of the difference between the guess measurement and the actual measurement is recomputed $\xi_m$. 

%Again the weighted spectral library is recomputed as well as the principal components. 

This continues after each measurement until either two things happen: 
\begin{enumerate}
	\item If the current $\ell_2$ norm of the difference between the guess and the actual measurement exceeds the last $\ell_2$ norm of the difference between guess and actual measurement by
	%
	\begin{equation}
		\xi_m > \xi_{m-1} - \frac{\sigma}{2}
	\end{equation}	
	%
	where $\sigma$ is the standard deviation of the system noise, which is assumed to be \gls{awgn}.

	\item Used the sixth principal component.
\end{enumerate}

when either of these two conditions are met, the loop resets to using the first principal component again. I constrained the algorithm to only use the first six principal components, because I noticed that the unmixing preformance is optimized when limited to only the first six principal components. Intuitively, this may be occuring because higher principal components tend exhibit lower SNR or because the spectra in the library do not exhibit significant high frequency features. This algorithm is called \acrfull{swpca}. It is important to note that as of yet, this algorithm does not consider the dispersion constraint of the \gls{afssi-c}, and therefore is more appropriate for the single pixel version, the \gls{afss}. The MATLAB code which simulates \gls{swpca} is found in Appendix \ref{app:adaptiveUnmixAlgo}.


\subsection{Hybrid Spectral Filters for the LCSI}\label{ssec:hybridFiltersLCSI}

The spectral filters produced by the \gls{lcsi} architecture are constrained by the physics of the birefringence dispersion created by the \gls{lcos}. For our particular model, the Holoeye PLUTO LCOS SLM, the spectral filter is changed by sending a different grayscale value to the green channel of the video input (Holoeye allows their SLM to be connected like a second monitor). Since there are 256 grayscale values (0-255), there are 256 different spectral filters, see \Cref{fig:slmSpectralFiltersVisible}. 

Since one is not able to design the spectral filters individually, the next best thing is to choose which spectral filters should be used at each measurement step. Intuitively, one can imagine that using the same spectral filter over and over again will lead to a measurement matrix $\mb{H}$ where the rows are linearly dependent. Instead, one should strive to construct a measurement that is highly incoherent to satisfy the \acrfull{rip}. 

For my experiment, I will compare several methods of choosing the spectral filters. The first method is simply selecting them at random from a discrete uniform distribution between 1 and 256, while constraining the selections to prevent using the same spectral filter from being used more than once. This technique however does not attempt to incorporate any prior knowledge about the statistics of the endmembers, besides sparsity. 

One attempt to incorporate the statistics of the endmembers is to use \gls{pca} to select the spectral filters. One could imagine an algorithm which computes the principal components of the endmembers (spectral library) and then selects the spectral filters which most closely resemble the principal component vector $\mb{p}$ based on their angle:
%
\begin{equation}
	\mb{h} = \argmaxA_{\mb{h}} \: \left\{ \frac{ \mb{p} }{ \| \mb{p} \| } \cdot \frac{ \mb{h} }{ \| \mb{h} \|  } \right\}.
\end{equation}
%
For the $m^{th}$ measurement, the spectral filter whose dot product is largest with the $m^{th}$ principal component of the endmember matrix is selected. However, using all the principal components actually increases the unmixing error after a certain amount of measurement steps, as compared to purely random selections. This occurs for several reasons: As the PC number increases, they actually become less informative. Second, principal components tend become more rapidly varying as the PC number increases, the spectral filters generated by the LCOS are in general smoothly varying and become more difficult to match with the higher principal components.

Thus, we created a hybrid spectral filter selection technique that uses \gls{pca} to select the first several spectral filters and then uses psuedo-random selections after a certain number of measurement steps. This balances the ability of \gls{pca} to choose spectral filters that improve the unmixing error at the initial measurement steps while using random selections to ensure the measurement matrix is incoherent enough to satisfy the \gls{rip}.

The hybrid approach to selecting the spectral filters is further extended to use a more advanced version of \gls{pca} called \acrfull{mnf} transform. \gls{mnf} was originally developed to remove noise from multispectral satellite images \cite{green1988transformation} and attempts to select a basis which orders the signal-to-noise ratio of the MNF components. However, \gls{mnf} is also used for Blind Signal Seperation (BSS), which is the seperation of a set of source signals from a set of mixed signals \cite{hundley2001solution}. Instead of computing the principal components, I compute the maximum noise fraction components of the spectral library. I specifically used the noise adjusted principle component analysis (NAPCA) algorithm to compute the MNF of the spectra library which is found in \cite{hundley2001solution}. The algorithm associates rapidly varying parts of the spectral library with noise and assumes the signal is contained in the smoothly varying parts of the spectral library. 

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.75]{slmSpectralFiltersVisible.pdf}
	\captionof{figure}[The normalized spectral filters created by the Holoeye PLUTO SLM and polarizing beam splitter]{The spectral filters created by the Holoeye PLUTO SLM and polarizing beam splitter. Each column is a spectral filter at a particular grayscale level (0-255) sent to the PLUTO SLM by a custom MATLAB program. }
	\label{fig:slmSpectralFiltersVisible}
\end{figure}


\section{Results}

\subsection{Simulation Results For the AFSS}

Now that I have discussed various coding strategies for spectral unmixing using the \gls{afss}, it is important quantify  them. I performed simulations over five \gls{snr} levels from $10^{-2}$ to $10^2$, where the \gls{snr} is defined as 
%
\begin{equation}
	\text{SNR} = \frac{ \text{E} \Big[ \text{Var}_{N_{\lambda}  \ap{ \mb{s} } } \Big] }{\sigma^2},
\end{equation}
%
which is the ratio of the average variance of the endmembers over the spectral channels to the noise variance. The results after 40 measurement steps are shown in \Cref{fig:unmixingTechniquesComparison}, which show the average \acrfull{rmse} of the estimated fractional abundance versus SNR. \gls{rmse} is defined as 
%
\begin{equation}
	\text{RMSE} =  \left[ \frac{1}{N_R} \sum_{r = 1}^{N_{R}} \ap{ \hat{a}_r - a_r }^2 \right]^{\frac{1}{2}}
\end{equation}
%
The purple dotted line represents the performance of a tunable filter architecture combined with the least-squares estimator (LSE). With random binary patterns, one can obtain an improvement of approximately 3$\times$ which demonstrates the advantage of multiplexing, as shown in the mustard dash-dotted line. By incorporating the prior knowledge of sparsity of the fractional abundance a futher improvement is also achieved, as shown in the orange dashed line. Finally, the blue solid line represents how adaptively designing the spectral filters and using compressive sensing provides an even better result than random coding alone. 

\Cref{fig:unmixingVsMeasurement} shows the average RMSE as a function of measurement number for SNR = 0.01, 1, and 100. The blue line represents psuedo-random spectral filters, the error decreases monotonically with measurement number as one would expect. The green lines represent what happens if the adaptive algorithm never went back to the first principal component once either of the two conditions in \Cref{sec:unmixingAlgo} are met. Simply using higher principle components does not reduce the RMSE after a certain point, even when the spectral library is weighted by the fractional abundance. The red line represents the adaptive algorithm as discussed. This demonstrates the importance of going back to the first principal component whenever the two conditions are met in the adaptive algorithm: it breaks the performance plateau and significantly reduces the unmixing error compared to random coding alone.

\begin{figure}
	\centering
	\includegraphics[scale=0.70]{unmixingTechniquesComparison.pdf}
	\captionof{figure}[Comparison of Spectral Unmixing Techniques for the AFSSI-C at five different SNR levels]{A comparison of spectral unmixing techniques for the AFSSI-C at five different SNR levels. The y-axis represents the average RMSE of the estimate fractional abundance. The x-axis represents the signal-to-noise in the measurements. The tunable filter LSE refers to the average unmixing performance if one were to use a tunable filter spectral imaging architectures with least squares estimation to estimate the fractional abundance. The random LSE line refers to the improvement in spectral unmixing This shows the improvement that multiplexing provides over simple tunable filter spectral imaging using the least squares estimator (LSE). Then using the multiplex advantage and algorithms that promote sparsity when the fractional abundance is known to be sparse, one can significantly outperform }
	\label{fig:unmixingTechniquesComparison}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.70]{unmixingVsMeasurement.pdf}
	\captionof{figure}[Comparison of Spectral Unmixing Techniques for the AFSSI-C versus Measurement Duration]{Comparison of Spectral Unmixing Techniques for the AFSSI-C versus Measurement Duration for SNR = 0.01, 1.0, and 100. Even though the spectral library is weighted by the fractional abundances from the last measurement, simply using every principal component underperforms using random spectral filters with $\ell_1$ regularized least squares (lasso). Switching the principal components according the algorithm described in \Cref{sec:unmixingAlgo} siginificantly reduces the unmixing error. }
	\label{fig:unmixingVsMeasurement}
\end{figure}


\subsection{Initial Experimental Results of Compressive Unmixing Using the AFSSI-C}

I performed an initial proof-of-principle experiment using the \gls{afssi-c} architecture. Due to the dispersion contrainst of the AFSSI-C, I was unable to test the adaptive algorithm, however the random coding and the use of sparsity promotting algorithms can still be demonstrated. 


For this experiment I had to upgrade the \gls{afssi-c} prototype by adding a second display, see \Cref{fig:unmixingArch1}. This is because the original prototype used only one LED computer monitor, so it can only display combinations of the same red, green, and blue (RGB) spectra, producing only three endmembers. In order to have six endmembers, I added an OLED display which also has red, green, and blue spectra but are different enough that they are not simply scaled versions of the RGB spectra from the LED monitor. This is shown in \Cref{fig:unmixingLibrary}. Note that the RGB spectra from the LED look different from \Cref{fig:afssicSpecLib} which was used for the \gls{afssi-c} experiment because the transmission from the pelicle beam splitter also acts as a spectral filter. 

\begin{figure}
	\centering
	\includegraphics[scale=0.70]{unmixingLibrary}
	\captionof{figure}[Six Endmember Spectra Used For Spectral Unmixing Experiment]{The six endmember spectra used for the spectral unmixing experiment. The library consist of the red, green, and blue spectra from an LED Monitor and the red, green, and blue spectra from the OLED. The LED monitor spectra may look different from the one shown in Chapter 4 since the spectra have been modified by transmitting through a pellicle beam splitter. }
	\label{fig:unmixingLibrary}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=1.00]{unmixingArch1.pdf}
	\captionof{figure}[Unmixing Architecture for Spectral Unmixing Experiment]{Experimental architecture used to superimpose the spectral images from the LED monitor, which already was in place, and an OLED display. ZEMAX was used to find the correct location of the achromatic doublet, OLED display, and pellicle beam splitter to ensure the intermediate image from both displays appeared at the same location and with the same transverse magnification.}
	\label{fig:unmixingArch1}
\end{figure}

The first-order optical architecture of the unmixing setup was carefully determined using a ray tracing and optimization software package called Zemax. The goal was to ensure that the intermediate image of the LED monitor and the intermediate image of the OLED were at the same location with the same image size. The two images effectively creates a single image which has spectrally mixed pixels with six possible endmembers. The pellicle beam splitter has a clear aperture of 2 inches, thus it needed to be close enough to the objective lens to minimize vignetting. A commercial off-the-shelf 120 mm EFL achromatic doublet from Edmund optics was placed between the OLED and the pellicle beam splitter to move the OLED closer to the instrument. Once all the optical components were optimized in Zemax, they were exported to Solidworks, see \Cref{fig:solidworksOfMixingSetupPicture}, where mounts for the achromatic doublet and the OLED display were designed for 3-D printing. 

There were several practical experimental issues that had to be addressed. Once the setup was constructed, I used a similar spectral calibration procedure from the \gls{afssi-c} experiment to determine the endmembers from the OLED display. The spatial calibration procedure was identical. The OLED was much brighter than the LED monitor, when measured by the SBIG camera. Second, even though the setup was optimized in Zemax, the actual alignment was imperfect. This caused the right side of the OLED to have a larger point-spread function than the left side of the monitor, which caused spatial cross-talk between neighboring pixels. To compensate for this, only one-fourth of the physical pixels were used in a single system pixel. Then a neutral density filter was placed front of the OLED to make the system pixel intensity on the same order-of-magnitude as the intensity from a system pixel from the monitor. Since the pellicle beam splitter acts as a partially reflecting mirror for OLED, I had to account for the image flip by writing a custom MATLAB function which accounts for the left-right flip. 

\begin{figure}
	\centering
	\includegraphics[scale=0.75]{solidworksOfMixingSetupPicture.png}
	\captionof{figure}[Computer Aided Design (CAD) drawing of experimental mixing setup.]{Computer Aided Design (CAD) drawing of experimental mixing setup. Various objects have been ``hidden'' to reduce clutter and emphasize the essential objects: the OLED, the custom design mount for the OLED, the achromatic doublet and the custom designed mount for the doublet, the pellicle beam splitter shown in a kinematic mount, the objective lens also in a custom fabricated C-mount lens.}
	\label{fig:solidworksOfMixingSetupPicture} 
\end{figure}

In order to perform an experiment which demonstrates the ability of the \gls{afssi-c} to perform unmixing on spectrally mixed images, I displayed a 32 $\times$ 32 green ramp on the monitor, see \Cref{fig:linearGreenRampImages}(a). The intensity of the green increases from left to right. The opposite image is displayed on the OLED display, see \Cref{fig:linearGreenRampImages}(b), the intensity of the green decreases from left to right. The other four endmembers which consists of the red and blue of each monitor are set to zero. The fractional abundance of green from both displays sum to one over the entire region-of-interest. 


\begin{figure}
	\centering
	\includegraphics[scale=0.75]{linearGreenRampImages.pdf}
	\captionof{figure}[Ground Truth Images for Spectral Unmixing Experiement]{Ground Truth Images for Spectral Unmixing Experiement. (a) A linear green ramp on the monitor. (b) A linear green ramp on the OLED. Remember that the green of each display are different.}
	\label{fig:linearGreenRampImages} 
\end{figure}

At each measurement step, the DMD is commanded to display a binary random pattern. Since the pattern is designed for $\{ -1, +1 \}$ values, I had to display the positive pattern, record the camera measurement, then display the negative pattern, and record another camera measurement, then subtract the negative from the positive camera images. This unfortunately introduces an additional factor of $\sqrt{\sigma}$ of measurement noise into each measurement step. Both the LSE and the MATLAB \texttt{lasso} function are used to estimate the fractional abundance. \Cref{fig:rmseVsMeasurementExperiment} shows the average RMSE versus measurement number over the 32 $\times$ 32 region. Unfortunately, due to time constraints, I was unable to develop a procedure to estimate the noise in the experiment, therefore the results cannot be directly compared to the simulation results. The result after the $40^{th}$ measurement is shown in \Cref{fig:linearGreenRampImagesExpResultMeas40} 

 By looking at an example pixel, see \Cref{fig:unmixingResultLinearGreenRamp3232}, one can see that the experiment properly identified the two endmembers that were actually present out of the six total endmembers and was able to accurately estimate the fractional abundance after five measurements. 


\begin{figure}[H]
	\centering
	\includegraphics[scale=0.65]{rmseVsMeasurementExperiment.pdf}
	\captionof{figure}[Average RMSE of 32 $\times$ 32 Experimental Spectral Unmixing Results Using the AFSSI-C]{32 $\times$ 32 Experimental Spectral Unmixing Results Using the AFSSI-C with random binary spectral filters. The MATLAB \texttt{lasso} function outperforms the least squares estimator as the number of measurements increase. Thus have an opportunity to beat traditional systems using significantly fewer measurements}
	\label{fig:rmseVsMeasurementExperiment} 
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.65]{linearGreenRampImagesExpResultMeas40.pdf}
	\captionof{figure}[Image of 32 $\times$ 32 Experimental Spectral Unmixing Results Using the AFSSI-C after the $40^{th}$ measurement.]{Image of 32 $\times$ 32 Experimental Compressive Spectral Unmixing Results Using the AFSSI-C after the $40^{th}$ measurement.}
	\label{fig:linearGreenRampImagesExpResultMeas40} 
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.65]{unmixingResultLinearGreenRamp3232.pdf}
	\captionof{figure}[Single Pixel Experimental Spectral Unmixing Results Using the AFSSI-C]{Single Pixel Spectral Unmixing Results with the AFSSI-C with random binary spectral filters. The MATLAB \texttt{lasso} function correctly identifies fractional abundance of the two green spectra from each display within five measurement steps. The four other spectra are estimated to be zero. }
	\label{fig:unmixingResultLinearGreenRamp3232} 
\end{figure}


\subsection{Simulation Results For the LCSI}

In order to accurately simulate the spectral filters I first performed a calibration procedure to measure how the each grayscale level filters an input spectrum. A high intensity custom-built white LED lamp was used to illuminate the \gls{lcsi}. At the output we placed an Ocean Optics USB 4000 spectrometer. Then the spectrum of the white light filtered by \gls{lcsi} at each grayscale level is recorded. Then the spectrum at each grayscale level is normalized by the maximum intensity at each wavelength which produces the calibration spectral filters shown in \Cref{fig:slmSpectralFiltersVisible}.

 In order to quantify the filter selection techniques discussed in \Cref{ssec:hybridFiltersLCSI}, I also produced several simulations. simulated the filter selection technique for SNR = 100. \Cref{fig:lcsiResults1} demonstrates the three techniques: randomly selecting filters, the hybrid PCA-Random filter selection, and the hybrid MNF-Random filter selection. Randomly selecting the filters adequately reduces the unmixing error monotonically with measurement error as expected. By using PCA to select the first six spectral filters the and then using a psuedo-random filter selection technique for the rest a significant performance gain is obtained wthin the first 20 measurements. As the number of measurement numbers increases, the probability of having used all the same spectral filters increases. At measurement 256, when all the spectral filters have been used, the average RMSE is the same. Using a hybrid MNF-Random filter selection produces an additional reduction in unmixing error.


\begin{figure}[H]
	\centering
	\includegraphics[scale=0.70]{lcsiResults1.pdf}
	\captionof{figure}[Comparing Random and Hybrid Spectral Filter Selections for the LCSI]{Comparing Random and Hybrid Spectral Filter Selections for the \gls{lcsi} at SNR = 100. One cannot generate arbitrary spectral filters with the \gls{lcsi}, therefore one must decide how to select from a set of 255 possible spectral filters. A hybrid of using the spectral filters that are closest in angle to the first six principal components and then using random filter selections outperforms purely random filter selections. Similarly, a hybrid of using the spectral filters that are closest in angle to the \gls{mnf} components for the first six measurement steps and then using random filter selections outperforms the random and the PCA-random hybrid filter selection. }
	\label{fig:lcsiResults1}
\end{figure}

\section{Conclusion}

Computational spectral unmixing is a computational sensing approach to estimating the fractional abundances of mixed spectra without the need to directly reconstruct the hyperspectral datacube. I discussed two separate architectures for spectral unmixing, the \gls{dmd} based \gls{afss} and the \gls{lcos} bases \gls{lcsi}. I developed two seperate approaches for coding the mixed spectral measurements for a compressing sensing approach for unmixing. The first used adaptive spectral filters combined with conditions to prevent the unmixing error from plateauing. The second relies on variation of \acrfull{pca} or \acrfull{mnf} to find spectral filters provide very informative measurements compared to simplying selecting spectral filters at random. Simulations show the viability these techniques to significantly reduce the unmixing error over naively random coding (or filter selection) alone, demonstrating the importance of incorporation the prior knowledge of the statistics of the signal-of-interest. 