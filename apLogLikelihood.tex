\chapter{Derivation of the Update Rule for Log-Likelihood Ratios}\label{app:Derivation of the LLR Update}

In order to update the conditional probability of the $i^{th}$ hypothesis given the full set of measurements $\{ g \}_m$ we can use Bayes' theorem

\begin{equation}
\mbox{P} \left( h_i | \{ g \}_m \right) = \frac{\mbox{P} \left( \{g\}_m |\, h_i \right) \; \mbox{P} \left(h_i\right)}{\mbox{P} \left( \{g\}_m \right)}.
\end{equation}


We really have no way of directly calculating $\mbox{P}\left( \left\{g\right\}_m \right)$. We can avoid the need to compute this by taking ratios. In our case, the ratio of the probability of the $i^{th}$ spectrum given the set of all measurements up to the current measurement $m$ $\left\{g_{m}\right\}$ to the probability of the $j^{th}$ spectrum given the set of all measurements up to the current measurement $m$ $\left\{g_{m}\right\}$ is

\begin{equation}
    L_{ij}^{\left\{ g \right\}_m}
    =
    \frac
    {
    \mbox{P}\left(\left\{ g \right\}_m\bigm\vert {h}_i\right)\mbox{P}\left({h}_i\right)
    }
    {
    \mbox{P}\left(\left\{ g \right\}_m\bigm\vert {h}_j\right)\mbox{P}\left({h}_j\right)
    }
\end{equation}
%
We will assume that the joint probability are independent and can be written as a product, thus we can rewrite the about equation as:
%
\begin{equation}
L_{ij}^{\left\{ g \right\}_m} =
{
    \mbox{P}( g_m \bigm\vert {h}_i ) \prod_{m'=1}^{m-1} \mbox{P}(g_{m'} \bigm\vert {h}_i ) \mbox{P}\left({h}_i\right)
\over
    \mbox{P}( g_m \bigm\vert {h}_j ) \prod_{m'=1}^{m-1} \mbox{P}(g_{m'} \bigm\vert {h}_i ) \mbox{P} \left({h}_j\right)
}
\end{equation}
%
If we define the ratio of likelihoods up to the last measurement $m-1$ as
%
\begin{equation}
    L_{ij}^{\left\{ g_{m-1} \right\}} =
    {
        \prod_{m'=1}^{m-1} \mbox{P}(g_{m'} \bigm\vert {h}_i ) \mbox{P}\left({h}_i\right)
    \over
        \prod_{m'=1}^{m-1} \mbox{P}(g_{m'} \bigm\vert {h}_i ) \mbox{P}\left({h}_j\right)
    }
\end{equation}
%
then we can write the equation for the update procedure as

\begin{equation}\label{eq:updateProcedure}
    L_{ij}^{\left\{ g \right\}_m} =
    {
        \mbox{P}( g_m \bigm\vert {h}_i )
    \over
        \mbox{P}( g_m \bigm\vert {h}_j )
    }
    L_{ij}^{\left\{ g_{m-1} \right\}}
\end{equation}

At the beginning before any measurements are taken, $m=0$, we have no bias towards any of the hypotheses. At $m = 0$

\begin{equation}\label{eq:uniformPrior1}
    L_{ij}^{g_0} =
    {
       \mbox{P}( {h}_i )
    \over
       \mbox{P}( {h}_j )
    }
\end{equation}

Since we have no bias we set all of our probabilities at $m=0$ to

\begin{equation}\label{eq:uniformPrior2}
    \mbox{P}( {h}_i)
    =
    \frac{1}{N}.
\end{equation}
%
In other words, each spectra is equiprobable. This is known as a ``uniform prior''. Thus before any measurements are made by definition:

\begin{equation}\label{eq:equiProb}
    L_{ij}^{ g_0 } = 1 \mbox{ for all } i,j
\end{equation}

We use a matrix to track the all the possible pairs of ratios. For example with a 3-class library

\begin{equation}
    \mathbf{L}^{\left\{ g \right\}_m}
    =
    \begin{bmatrix}
      L_{11}^{\left\{ g \right\}_m}  & L_{12}^{\left\{ g \right\}_m}  & L_{13}^{\left\{ g \right\}_m}  \\
      L_{21}^{\left\{ g \right\}_m}  & L_{22}^{\left\{ g \right\}_m}  & L_{23}^{\left\{ g \right\}_m}  \\
      L_{31}^{\left\{ g \right\}_m}  & L_{32}^{\left\{ g \right\}_m}  & L_{33}^{\left\{ g \right\}_m}
    \end{bmatrix}
\end{equation}
%
Based on the eq.~\ref{eq:equiProb}, the initial likelihood ratio matrix at the measurement step $m = 0$ is

\begin{equation}
    \mathbf{L}^{ g_1 }
    =
    \begin{bmatrix}
      1  & 1 & 1 \\
      1  & 1 & 1 \\
      1  & 1 & 1
    \end{bmatrix}
\end{equation}

Now that we have our initial conditions, and our update procedure from eq~\ref{eq:updateProcedure}, we still haven't discussed a way to calculate $P(g_m|{h}_i)$, the probability of observing a measurement $g_m$ given that the $i^{th}$ spectrum is the true spectrum. This is where we introduce our noise model. The noise model, gives the probability of the measurement we just made $g_m$, if we assume some Gaussian noise distribution $\mathscr{N}(0,\sigma)$.

\begin{equation}\label{eq:noiseModel}
    \mbox{P}(g_m|{h}_i)
    =
    \frac
    {
        1
    }
    {
        \sqrt{2\pi \sigma^2}
    }
    \exp{
    \left[
        -
        \frac
        {
        \left( g_m - \mb{t}_m \cdot \mb{s}_i \right)^2
        }
        {
        2 \sigma^2
        }
    \right]
    }
\end{equation}

Remember $g_m$ is the noisy measurement and $\mb{t}_m$ is the spectral code realized by the DMD pattern. For example, a given measurement number $m$, in the case of 3 possible spectra the inner products $\mb{t}_m \cdot \mb{s}_1$, $\mb{t}_m \cdot \mb{s}_2$, $\mb{t}_m \cdot \mb{s}_3 $ will all have different values. These inner products are deterministic because $\mb{t}_m$ is something we choose and $\mb{s}_l$ for $m' = 1,2,3$ comprise our library and by definition are constant. Plug these inner products into the equation above assuming a given $\sigma$, and we will get different values of $\mbox{P}(g_m | h_1)$, $\mbox{P}(g_m | h_2)$, and $\mbox{P}(g_m | h_3)$

%\begin{figure}
%    \centering
%    \includegraphics[scale=0.4]{noisemodelpic1.png}
%     \caption[Plot of the probability distribution function for 3 spectra in a hypothetical library]
%   {Plot of the probability distribution function for 3 spectra in a hypothetical library. Each p.d.f. is used to compute the probability that the $l^{th}$ spectrum is the true spectrum.}
%\end{figure}

In the picture above we see have 3 Gaussian distributions for each of the 3 possible spectra. The measurement $g_1 = \mb{t}_1 \cdot \mb{s}_{true} + \mathscr{N}(0,\sigma_a) \approx 0.05$ as shown on the horizontal axis. Where this intercepts the functions gives the values of the probability of the measurement given knowledge of each spectrum.

\begin{equation}
    \mbox{P}(g_1|s_1)
    =
    \frac
    {
        1
    }
    {
        \sqrt{2\pi \sigma^2}
    }
    \exp{
    \left[
        -
        \frac
        {
        \left( g_1 - \mb{t}_1 \cdot s_1 \right)^2
        }
        {
        2 \sigma^2
        }
    \right]
    }
    \approx
    0.30
\end{equation}
\begin{equation}
    \mbox{P}(g_1|s_2)
    =
    \frac
    {
        1
    }
    {
        \sqrt{2\pi \sigma^2}
    }
    \exp{
    \left[
        -
        \frac
        {
        \left( g_1 - \mb{t}_1 \cdot s_2 \right)^2
        }
        {
        2 \sigma^2
        }
    \right]
    }
    \approx
    0.40
\end{equation}
\begin{equation}
    \mbox{P}(g_1|s_3)
    =
    \frac
    {
        1
    }
    {
        \sqrt{2\pi \sigma^2}
    }
    \exp{
    \left[
        -
        \frac
        {
        \left( g_1 - \mb{t}_1 \cdot s_3 \right)^2
        }
        {
        2 \sigma^2
        }
    \right]
    }
    \approx
    0.26
\end{equation}


The likelihood ratios become:

\begin{equation}
    L_{12}^{ g_=1 }
    =
    \frac
    {
        \mbox{P}(g_1|h_1)
    }
    {
        \mbox{P}(g_1|h_2)
    }
    \approx
    .13
\end{equation}
\begin{equation}
    L_{13}^{ g_=1 }
    =
    \frac
    {
        \mbox{P}(g_1|h_1)
    }
    {
        \mbox{P}(g_1|h_3)
    }
    \approx
    0.25
\end{equation}
\begin{equation}
    L_{23}^{ g_=1 }
    =
    \frac
    {
        \mbox{P}(g_1|h_2)
    }
    {
        \mbox{P}(g_1|h_3)
    }
    \approx
    1.9
\end{equation}

The diagonal will always be $1$ and the elements $L_{21}^{\left\{ g_m=1 \right\}}$, $L_{31}^{\left\{ g_m=1 \right\}}$, and $L_{32}^{\left\{ g_m=1 \right\}}$ are just the inverse of the upper right elements in the likelihood ratio matrix.

\begin{equation}
    \mathbf{L}^{g_1}
    =
    \begin{bmatrix}
      1.0  & 0.7 & 1.2 \\
      1.3  & 1.0 & 1.6 \\
      0.9  & 0.6 & 1.0
    \end{bmatrix}
\end{equation}

For $m=2$ use the update procedure
\begin{equation}
    L_{ij}^{\left\{ g_2, g_1 \right\}} =
    {
        \mbox{P}( g_2 \bigm\vert {h}_i )
    \over
        \mbox{P}( g_2 \bigm\vert {h}_j )
    }
    L_{ij}^{g_1}
\end{equation}

\noindent then store the data back into the likelihood ratio matrix.

However during computing, exponentials often cause numerical problems. In MATLAB 2013b, the exponential of a number larger than approximately 709 is so large that MATLAB simply call them infinity (Inf). If these are in the denominators of the likelihood ratios then computers will simply call them not a number (NaN). To avoid, these computational issues use the logserious-likelihood ratio to eliminate the exponentials

\begin{equation}
    \mathscr{L}_{ij}^{\left\{g_m\right\}}
    =
    \ln{
        \left[
            L_{ij}^{\left\{g_m\right\}}
        \right]
    }
    =
    \ln{
    \left[
        \frac
        {
            \mbox{P}(\left\{ g \right\}_m|{h}_i)\mbox{P}({h}_i)
        }
        {
            \mbox{P}(\left\{ g \right\}_m|{h}_j)\mbox{P}({h}_j)
        }
    \right]
    }
\end{equation}

\begin{equation}
    \mathscr{L}_{ij}^{\left\{g_m\right\}}
    =
    \ln{
        \left[
            \frac
            {
                \mbox{P}( g_m |{h}_i)
            }
            {
                \mbox{P}( g_m |{h}_j)
            }
            L_{ij}^{\left\{g_{m-1}\right\}}
        \right]
    }
\end{equation}

We will now derive a simple update procedure. The log of a product is the sum of the logs and we can rewrite the last term:

\begin{equation}
    \mathscr{L}_{ij}^{\left\{g_m\right\}}
    =
    \ln{
        \left[
            \frac
            {
                \mbox{P}( g_m |{h}_i)
            }
            {
                \mbox{P}( g_m |{h}_j)
            }
        \right]
    }
    +
    \mathscr{L}_{ij}^{\left\{g_{m-1}\right\}}
\end{equation}

\noindent The log of a division is the difference of the logs.

\begin{equation}
    \mathscr{L}_{ij}^{\left\{g_m\right\}}
    =
    \ln{
        \left[
            \mbox{P}( g_m |{h}_i)
        \right]
    }
    -
    \ln{
        \left[
            \mbox{P}( g_m |{h}_j)
        \right]
    }
    +
    \mathscr{L}_{ij}^{\left\{g_{m-1}\right\}}
\end{equation}

\noindent Plug in equation~\ref{eq:noiseModel} for the conditional probabilities.

\begin{multline}
    \mathscr{L}_{ij}^{\left\{g_m\right\}}
    =
    \ln{
        \left\{
            \frac
            {
                1
            }
            {
                \sqrt{2\pi \sigma^2}
            }
            \exp{
            \left[
                -
                \frac
                {
                \left( g_m - f_m \cdot {h}_i \right)^2
                }
                {
                2 \sigma^2
                }
            \right]
            }
        \right\}
    }
    \\
    -
    \ln{
        \left\{
            \frac
            {
                1
            }
            {
                \sqrt{2\pi \sigma^2}
            }
            \exp{
            \left[
                -
                \frac
                {
                \left( g_m - f_m \cdot {h}_j \right)^2
                }
                {
                2 \sigma^2
                }
            \right]
            }
        \right\}
    }
    +
    \mathscr{L}_{ij}^{\left\{g_{m-1}\right\}}
\end{multline}

\noindent Continue expanding the number of terms in order to find terms that will cancel.

\begin{multline}
    \mathscr{L}_{ij}^{\left\{g_m\right\}}
    =
    \ln{
        \left\{
            \frac
            {
                1
            }
            {
                \sqrt{2\pi \sigma^2}
            }
        \right\}
    }
    +
    \ln{
    \left\{
            \exp{
            \left[
                -
                \frac
                {
                \left( g_m - f_m \cdot {h}_i \right)^2
                }
                {
                2 \sigma^2
                }
            \right]
            }
        \right\}
    }
    \\
    -
    \ln{
        \left\{
            \frac
            {
                1
            }
            {
                \sqrt{2\pi \sigma^2}
            }
        \right\}
    }
    -
    \ln{
    \left\{
            \exp{
            \left[
                -
                \frac
                {
                \left( g_m - f_m \cdot {h}_i \right)^2
                }
                {
                2 \sigma^2
                }
            \right]
            }
        \right\}
    }
    +
    \mathscr{L}_{ij}^{\left\{g_{m-1}\right\}}
\end{multline}

\noindent Two terms cancel. The natural log of an exponential is just the argument of the exponential.

\begin{equation}\label{eq:LLRUpdate}
    \mathscr{L}_{ij}^{\left\{g_m\right\}}
    =
    -
    \frac
    {
        \left( g_m - f_m \cdot {h}_i \right)^2
    }
    {
        2 \sigma^2
    }
    +
    \frac
    {
        \left( g_m - f_m \cdot {h}_j \right)^2
    }
    {
        2 \sigma^2
    }
    +
    \mathscr{L}_{ij}^{\left\{g_{m-1}\right\}}
\end{equation}

\begin{equation}\label{eq:LLRUpdate2}
    \boxed{
        \mathscr{L}_{ij}^{\left\{g_m\right\}}
        =
        \mathscr{L}_{ij}^{g_m}
        +
        \mathscr{L}_{ij}^{\left\{g_{m-1}\right\}}
    }
\end{equation}


\noindent As you can see we now have a simplified update procedure which only requires addition to the previous set of log-likelihood ratios. We have completely avoided the computing the exponential of larger numbers!

Now that we have the newly updated log-likelihood ratios $ \mathscr{L}_{ij}^{\left\{g_m\right\}} $, we can calculate the newly updated probabilities of each candidate spectra $\mbox{P}({h}_i | {g_m})$.

We will discuss an example that shows how we begin the update procedure after the first measurement. For $m = 1$

\begin{equation}
    \mathscr{L}_{ij}^{g_1}
    =
    -
    \frac
    {
        \left( g_1 - f_m \cdot {h}_i \right)^2
    }
    {
        2 \sigma^2
    }
    +
    \frac
    {
        \left( g_1 - f_m \cdot {h}_j \right)^2
    }
    {
        2 \sigma^2
    }
    +
    \mathscr{L}_{ij}^{g_{0}}
\end{equation}


\noindent From equation~\ref{eq:uniformPrior1} and~\ref{eq:uniformPrior2} we know that $L_{ij}^{g_{0}} = 1$. The natural log of 1 is 0.

\begin{equation}
    \mathscr{L}_{ij}^{g_{0}}
    =
    \ln{
    \left(
        L_{ij}^{g_{0}}
    \right)
    }
    =
    \ln{
    \left(
        1
    \right)
    }
    =
    0
\end{equation}

\noindent We now have an equation that we can use to begin our update procedure
\begin{equation}
    \mathscr{L}_{ij}^{g_1}
    =
    -
    \frac
    {
        \left( g_1 - f_m \cdot {h}_i \right)^2
    }
    {
        2 \sigma^2
    }
    +
    \frac
    {
        \left( g_1 - f_m \cdot {h}_j \right)^2
    }
    {
        2 \sigma^2
    }
\end{equation}





\section{Calculating the Conditional Probabilities from the Log-Likelihood Ratio Matrix}

Similar to the likelihood ratio matrix, the log-likelihood ratio matrix is used to keep track of the ratio of the probabilities of each hypothesis.

After each measurement $m$, each log-likelihood ratio is updated using equation ~\ref{eq:LLRUpdate2}

Then the conditional probabilities of each hypothesis $\mbox{P}(h_l | \left\{ g \right\}_m)$ can be calculated using the following algorithm:

\begin{enumerate}
    %
    \item Determine the row of with the maximum element
    %
    \begin{equation}
    \texttt{maxRow := } \texttt{findRow}(\pmb{\mathscr{L}}^{\left\{ g \right\}_m}))
    \end{equation}
    %
    \item Once you know the row, get the corresponding column
    %
    \begin{equation}
    \mathscr{L}_{i,\texttt{maxRow}}^{ \left\{ g_{m} \right\} }
    \end{equation}
    %
    \item Take the exponentials for all the elements in that column. To get the unnormalized probabilities.
    %
    \begin{equation}
    \exp ( \mathscr{L}_{i,\texttt{maxRow}}^{ \left\{g_{m} \right\} } )
    \end{equation}
    %
    \item Normalize probabilities assuming all the denominators are equal to 1 and then by dividing each element by the sum
    %
    \begin{equation}
    \mbox{P}(h_l | \left\{ g \right\}_m )
    =
    \frac
    {
        \exp ( \mathscr{L}_{i,\texttt{maxRow}}^{ \left\{g_{m} \right\} } )
    }
    {
        \sum_{i = 1}^{N_R} \exp ( \mathscr{L}_{i,\texttt{maxRow}}^{ \left\{g_{m} \right\} } )
    }
    \end{equation}
    %
    \item The true spectrum is the hypothesis with the largest probability.
    %
    \begin{equation}
        s_{true} := \texttt{max}\left[\mbox{P}(s_{l}) \right]
    \end{equation}
    %
\end{enumerate}

