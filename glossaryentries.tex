

%%%%%%%%%%%%%%%%%%%%%%%%%%% Define acronyms here% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newacronym{svm}{SVM}{support vector machine}
\newacronym[plural=FPAs,firstplural=focal-plane arrays (FPAs)]{fpa}{FPA}{focal-plane array}
\newacronym{psf}{PSF}{point spread function}
\newacronym{adc}{ADC}{analog-to-digital converter}
\newacronym{afssi-c}{AFSSI-C}{Adaptive Feature Specific Spectral Imaging-Classifier}
\newacronym{pca}{PCA}{Principal Component Analysis}
\newacronym{LENS}{LENS}{Laboratory for Engineering Non-Traditional Sensors}
\newacronym{scout}{SCOUT}{Static Computational Optical Undersampled Tracker}
\newacronym{disp}{DISP}{Duke Imaging and Spectroscopy Program}
\newacronym{lcos}{LCOS}{Liquid Crystal on Silicon}
\newacronym{slm}{SLM}{Spatial Light Modulator}
\newacronym{snr}{SNR}{signal-to-noise ratio}
\newacronym{swap-c}{SWAP-C}{size, weight and power-cost}
\newacronym{ct}{CT}{Computed Tomography}
\newacronym{spect}{SPECT}{Single-Photon Emission Computed Tomography}
\newacronym{pet}{PET}{Positron Emission Tomography}
\newacronym{mri}{MRI}{Magnetic Resonance Imaging}
\newacronym{radar}{Radar}{RAdio Detection And Ranging}
\newacronym{sar}{SAR}{Synthetic Aperture Radar}
\newacronym{ccd}{CCD}{Charge-Coupled Device}
\newacronym{cmos}{CMOS}{Complementary Metal–Oxide–Semiconductor}
\newacronym{cassi}{CASSI}{Coded Aperture Snapshot Spectral Imaging}
\newacronym{dmd}{DMD}{Digital Micro-Mirror Display}
\newacronym{cosi}{COSI}{Computational Optical Sensing and Imaging}
\newacronym{mse}{MSE}{Mean Squared Error}
\newacronym{rmse}{RMSE}{Root corollaryMean Squared Error}
\newacronym{fts}{FTS}{Fourier Transform Spectrometer}
\newacronym{map}{MAP}{Maximum A Posteriori}
\newacronym{rip}{RIP}{restricted isometry property}
\newacronym{ls}{LS}{least squares}
\newacronym{osa}{OSA}{Optical Society of America}
\newacronym{lar}{LAR}{Least Angle Regression}
\newacronym{afss}{AFSS}{Adaptive Feature Specific Spectrometer}
%\newacronym{lasso}{LASSO}{Least Absolute Shrinkage and Selection Operator}


%%%%%%%%%%%%%%%%%%% Define symbols here %%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newglossaryentry{specres}{type=symbols, name={$ \delta_{\lambda} $}, symbol={$ \delta_{\lambda} $} ,sort=delta, description={Spectral resolution}}

\newglossaryentry{numspecchan}{type=symbols,name={$ N_{\lambda} $}, symbol={$ N_{\lambda} $},sort=Nlambda, description={Number of spectral channels}}

\newglossaryentry{measvec}{type=symbols,name={$ \mathbf{g} $}, symbol={$ \mathbf{g} $},sort=g, description={Measurement vector}}

\newglossaryentry{objvec}{type=symbols,name={$ \mathbf{f} $}, symbol={$ \mathbf{f} $},sort=f, description={Object signal-of-interest}}

\newglossaryentry{estobjvec}{type=symbols,name={$ \mathbf{ \hat{ f }} $}, symbol={$ \mathbf{ \hat{ f }} $},sort=fhat, description={Estimated object}}

\newglossaryentry{hadamardn}{type=symbols,name={$ \mathbf{ H }_N $}, symbol={$ \mathbf{ H }_N $}, sort=Hn, description={A Hadamard matrix of size $N \times N$}}

\newglossaryentry{H}{type=symbols,name={$ \mathbf{ H } $}, symbol={$ \mathbf{ H } $}, sort=H, description={The system matrix which captures all of the physical phenomena in a measurement. Also called the measurement matrix.}}

\newglossaryentry{noisevec}{type=symbols,name={$ \mathbf{ e } $}, symbol={$ \mathbf{ e } $}, sort=e, description={Additive noise vector}}

\newglossaryentry{nummeas}{type=symbols,name={$ N_{m} $}, symbol={$ N_{m} $}, sort=Nm, description={Total number of measurements}}

\newglossaryentry{m}{type=symbols,name={$ m $}, symbol={$ m $}, sort=m, description={measurement number/index}}

\newglossaryentry{n}{type=symbols,name={$ n $}, symbol={$ n $}, sort=n, description={The number of elements in the object \gls{objvec} }}

\newglossaryentry{A}{type=symbols,name={$ \mb{A} $}, symbol={$ \mb{A} $}, sort=A, description={The product of the sensing matrix and the representation matrix $\mb{A} = \mb{H}\mb{\Psi}$ }}

\newglossaryentry{l1}{type=symbols,name={ $\ell_1$ }, symbol={ $\ell_1$ }, sort=l1, description={The $\ell_1$ is a norm which is defined as the sum of the absolute values of the entries a vector}}

\newglossaryentry{tau}{type=symbols,name={ $\tau$ }, symbol={ $\tau$ }, sort=tau, description={Notation for a regularization parameter in an objective function for any kind of optimization}}


%%%%%%%%%%%%%%%%%% Define new terms in the glossary %%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newglossaryentry{isomorphic sensing}
{
name={Isomorphic sensing},
text={isomorphic sensing},
description={An isomorphic sensor is any sensor that attempts to produce measurement data that resembles the signal-of-interest. An isomorphic measurement is a measurement that resembles the signal-of-interest. An isomorphic measurement can be described as a one-to-one mapping from the signal-of-interest to the measurement, and is represented in matrix notation with an identity matrix. Isomorphic sensing is synonomous with traditional sensing.}
}

\newglossaryentry{isomorphic}
{
name={Isomorphic},
text={isomorphic},
description={\emph{See} \gls{isomorphic sensing}}
}

\newglossaryentry{isomorphic sensor}
{
name={Isomorphic sensor},
text={isomorphic sensor},
plural={isomorphic sensors},
description={\emph{See} \gls{isomorphic sensing}}
}

\newglossaryentry{traditional sensing}
{
name={Traditional sensing},
text={traditional sensing},
description={\emph{See} \gls{isomorphic sensing}}
}

\newglossaryentry{multiplex sensing}
{
name={multiplex sensing},
description={A multiplexing sensor is any sensor that attempts to combine the physical phenomena of the analog signal-of-interest in to a few or one analog-to-digital sample to overcome limits due to signal-to-noise ratio. The measurement data that does resemble the signal-of-interest. A matrix representation of a multiplex measurement will not look like an identity matrix}
}

\newglossaryentry{multiplexing}
{
name={Multiplexing},
text={multiplexing},
description={ \emph{See} \gls{multiplex sensing}}
}

\newglossaryentry{indirect-imaging}
{
name={Indirect-imaging},
text={indirect-imaging},
description={An imaging sensor that attempts to reconstruct an image of an object using non-isomorphic measurements. A computational step is required to reconstruct the object signal-of-interest. X-Ray \gls{ct} and \gls{sar} are examples types of indirect-imaging.  }
}

\newglossaryentry{task-specific sensing}
{
name={Task-specific sensing},
text={task-specific sensing},
description={A sensor that does not attempt to reconstruct the signal-of-interest to perform a signal processing task such as detection, estimation, and classification. The \gls{afssi-c} is an example of a task-specific sensor. }
}

\newglossaryentry{compressive sensing}
{
name={Compressive sensing},
text={compressive sensing},
description={A sensing technique that attempts to directly a compressive or sparse representation of the signal-of-interest during the measurement. Compressive sensors attempt to uses significantly less measurements than the dimensionality of the signal-of-interest. Compressive sensing relies on non-linear optimization algorithms to perform reconstruction or task-specific sensing from highly underdetermined inverse problems. These algorithms often rely on sparsity to avoid overfitting.}
}

\newglossaryentry{sparsity}
{
name={sparsity},
text={sparsity},
description={A set, vector, or matrix which contains an overwhelming majority of zeros relative to the size of the set, vector, or matrix. }
}



\newglossaryentry{compressive sensors}
{
name={Compressive sensors},
plural={compressive sensors},
%text={compressive sensors},
description={ \emph{See} \gls{compressive sensing}}
}

\newglossaryentry{compressive sampling}
{
name={Compressive sampling},
plural={compressive sampling},
text={compressive sampling},
description={ \emph{See} \gls{compressive sensing}}
}

\newglossaryentry{computational sensing}
{
name={Computational sensing},
text={computational sensing},
description={Any sensing technique in which the sensor uses \gls{indirect-imaging}, \gls{multiplex sensing}, \gls{compressive sensing}, or \gls{task-specific sensing}.}
}

\newglossaryentry{computational sensor}
{
name={Computational sensor},
text={computational sensor},
plural={computational sensors},
description={ \emph{See} \gls{computational sensing}}
}


\newglossaryentry{measurement}
{
name={Measurement},
text={measurement},
description={A process that converts a physical phenomena to single datum or a set of data. In the context of this dissertation it used synonomously with the detector readout.}
}

\newglossaryentry{monochromator}
{
name={monochromator},
text={monochromator},
plural={monochromator},
description={An optical instrument that transmits a selectable narrow wavelength band of light chosen from a wider range of wavelengths available at the input.}
}

\newglossaryentry{pixel pitch}
{
name={Pixel pitch},
text={pixel pitch},
description={The center to center distance between pixels on a focal-plane array such as a CCD or CMOS image sensor.}
}

\newglossaryentry{spectral resolution}
{
name={Spectral resolution},
text={spectral resolution},
description={The smallest the smallest difference in wavelength the instrument or sensor can discern.}
}

\newglossaryentry{data processing inequality}
{
name={Data processing inequality},
text={data processing inequality},
description={An theorem from information theory that proves the information of a signal cannot be increased via a local physical operation.}
}

\newglossaryentry{coding}
{
name={Coding},
text={coding},
description={In the context of computational sensing, coding is the process of modifying or modulating an analog signal during measurement. Coding is often used to reduce degeneracy in the measurement data. In the context of spectroscopy, the spectral filters act to code the spectrum.  }
}

\newglossaryentry{code}
{
name={Code},
text={code},
description={ \emph{See} \gls{coding}}
}

\newglossaryentry{forward model}
{
name={Forward model},
text={forward model},
description={A numerical model, typically an equation, that explains the mapping of the analog signal-of-interest to the measurement data.}
}

\newglossaryentry{inverse problem}
{
name={Inverse problem},
text={inverse problem},
description={The problem of taking the measurement data and calculating a reconstruction of the signal-of-interst or task-specific parameters. In computational sensing, computer algorithms are used to solve inverse problems.}
}

\newglossaryentry{sparse}
{
name={Sparse},
text={sparse},
description={ \emph{See} \gls{sparsity}}
}

\newglossaryentry{sample}
{
name={Sample},
text={sample},
description={ The process of mapping a continuous signal to a discrete signal.  }
}

\newglossaryentry{sampling}
{
name={Sampling},
text={sampling},
description={ \emph{See} \gls{sample}  }
}



\newglossaryentry{multiplex advantage}
{
name={Multiplex advantage},
text={multiplex advantage},
description={The improvement in \gls{snr} that is due to multiplexed measurements rather than isomorphic measurements. This is often referred to as the Fellgett advantage since it was first discovered by Peter Fellgett. \emph{See} \gls{multiplex sensing}} 
}

\newglossaryentry{Fellgett advantage}
{
name={Fellgett advantage},
text={Fellgett advantage},
description={\emph{See} \gls{multiplex advantage}} 
}

\newglossaryentry{bandlimited signal}
{
name={Bandlimited signal},
text={bandlimited signal},
description={A bandlimited signal is any signal $ g(x) $ that whose Fourier transform $ G(f_x) $ is zero and remains zero past a certain frequency $ \lvert f_x \rvert \geq B$.} 
}

\newglossaryentry{basis pursuit}
{
name={Basis pursuit},
text={basis pursuit},
description={Algorithms which attempt to solve a compressive sensing problem by solving the convex optimization problem of 
\begin{equation}
	\mbh{x} = \argminA_{\mb{x}} \: \| \mb{x} \|_{1} \text{\; subject to \;} \mb{A}\mb{x} = \mb{g}
\end{equation} 
}
}

\newglossaryentry{incoherence}
{
name={Incoherence},
text={incoherence},
description={ The idea that }
}

\newglossaryentry{compressible}
{
name={Compressible},
text={compressible},
description={ The idea that }
}

\newglossaryentry{representation basis}
{
name={Representation basis},
text={representation basis},
description={ The idea that representation basis}
}

\newglossaryentry{posterior}
{
name={Posterior},
text={posterior},
description={ The posterior probability is the conditional probability of a hypothesis $h$ or parameter $\theta$ given some data $g$. $ P \left( \theta \given[\big] g \right) $}
}

\newglossaryentry{prior}
{
name={Prior},
text={prior},
description={ The priori probability is the probability of a hypothesis $h$ or parameter $\theta$ without any knowledge of the data data $g$. $ P \left( \theta \right) $}
}

\newglossaryentry{likelihood}
{
name={Likelihood},
text={likelihood},
description={ The likelihood is the probability of the data $g$ assuming that a hypothesis $h$ or parameter $\theta$ is true. $P \left( g \given[\big] \theta \right)$}
}

\newglossaryentry{Maximum A Posteriori}
{
name={Maximum A Posteriori (MAP)},
text={Maximum A Posteriori (MAP)},
description={Maximum A Posteriori (MAP) estimator says the parameters  $ \mb{\theta} $ which maximize the \gls{posterior} probability are the most likely parameters.}
}

\newglossaryentry{lasso}
{
name={lasso},
text={lasso},
description={The least absolute shrinkage and selection operator (lasso) is a regression analysis method that performs both variable selection and regularization. It is refers to an optimization problem, a regression technique, and an algorithm. The lasso problem is the
%
\begin{equation}
	\mbh{x} = \argminA_{\mb{x}} \: \| \mb{Ax} = \mb{g} \|_{2}^{2} + \tau \| \mb{x} \|_1
\end{equation}
 }
}

\newglossaryentry{ridge regression}
{
name={ridge regression},
text={ridge regression},
description={Ridge regression is a regression technique that uses $\ell_2$ regularization to prevent overfitting of the data. Ridge regression seeks coefficient estimates that fit the data well by making the objective function, the $\ell_2$ norm between the data and the linear model small, however the shrinkage penalty has the effect of shrinking estimates towards zero. 
%
\begin{equation}
	\mbh{x} = \argminA_{\mb{x}} \: \| \mb{Ax} = \mb{g} \|_{2}^{2} + \tau \| \mb{x} \|_2
\end{equation}
 }
}

